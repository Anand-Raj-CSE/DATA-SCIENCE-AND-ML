{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577c954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0705b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3 # number of features\n",
    "layers = [4,3] # NUmber of neurons in the first and the second layer\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d6199",
   "metadata": {},
   "source": [
    "# Defining a Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d057a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# Defining softmax helper function\n",
    "def softmax(a):\n",
    "    \"\"\"Softmax is a function that does e^a(i)/sum(e^a(i)) , suppose a=[1,2,3] then its softmax would be e^1/(e^1+e^2+e^3) , \n",
    "    e^2/(e^1+e^2+e^3), e^3/(e^1+e^2+e^3). Here we can see that the sum is going to be 1 for all the values that we have we have \n",
    "    calculated so far.\n",
    "    \"\"\"\n",
    "    e_pa = np.exp(a) # numpy does broadcasting for a vector so e_pa is a vector\n",
    "    ans = e_pa/np.sum(e_pa,axis=1,keepdims=True) # axis is 0 for colums which is by default and axis 1 is for rows. Keepdims explained below\n",
    "    return ans\n",
    "\n",
    "a = np.array([[10,10],[20,20]])\n",
    "a_ = softmax(a)\n",
    "print(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f29a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd520bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[7 7 7]\n",
      "[ 6 15]\n",
      "[[7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[6,5,4]])\n",
    "print(np.sum(a)) # This would give us the sum of all the elements in the 2d vector.\n",
    "print(np.sum(a,axis=0)) # Sum of all the columns\n",
    "print(np.sum(a,axis=1)) # Sum of all the elements along the row\n",
    "# Now keepdims just preservs the shape of the array\n",
    "print(np.sum(a,axis=0,keepdims=True)) # This would return thr sum along the columns in a 2d vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43eb3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self,input_size,output_size):\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        model = {}\n",
    "        \n",
    "        # First Layer\n",
    "        model['w1'] = np.random.randn(input_size,layers[0]) #this would generate a normal distribution.\n",
    "        model['b1'] = np.zeros((1,layers[0]))\n",
    "        \n",
    "        #Second Layer\n",
    "        model['w2'] = np.random.randn(layers[0],layers[1]) \n",
    "        model['b2'] = np.zeros((1,layers[1]))\n",
    "        \n",
    "        #Third Layer/Output layer\n",
    "        model['w3'] = np.random.randn(layers[1],output_size) \n",
    "        model['b3'] = np.zeros((1,output_size))\n",
    "        \n",
    "        self.model=model\n",
    "        \n",
    "        \n",
    "    # Defining forward propagation\n",
    "    def forward(self,x):\n",
    "        \n",
    "        W1,W2,W3 = self.model['W1'],self.model['W2'],self.model['W3']\n",
    "        b1,b2,b3 = self.model['b1'],self.model['b2'],self.model['b3']\n",
    "        \n",
    "        z1 = np.dot(x,W1)+b1\n",
    "        a1 = np.tanh(z1) # tanh is a function like sigmoid as it converts any input in range -1 to 1, sigmoid does in range 0 and 1\n",
    "        \n",
    "        z2 = np.dot(a1,W2)+b2\n",
    "        a2 = np.tanh(z2)\n",
    "        \n",
    "        z3 = np.dot(a2,W3)+b3\n",
    "        y_ = softmax(z3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3b154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.33385865  1.40719915 -1.83330746  1.31613022]\n",
      " [-0.69709161 -1.02259691  0.4585747   1.85202931]\n",
      " [-0.468795    1.02537599 -0.97798401  0.82079649]]\n"
     ]
    }
   ],
   "source": [
    "weg = np.random.randn(input_size,layers[0])\n",
    "print(weg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd866b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd5ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
